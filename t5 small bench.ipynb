{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install rouge_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T08:06:43.043805Z","iopub.execute_input":"2024-12-25T08:06:43.044143Z","iopub.status.idle":"2024-12-25T08:06:49.142417Z","shell.execute_reply.started":"2024-12-25T08:06:43.044115Z","shell.execute_reply":"2024-12-25T08:06:49.141522Z"}},"outputs":[{"name":"stderr","text":"/usr/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Collecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\nBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=deed6c9f1bab4eccf5ce67f8fae5abe0e360d76b61339dfcd7af3300d01346ba\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score\nSuccessfully installed rouge_score-0.1.2\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport torch\nfrom datasets import load_dataset\nfrom transformers import (\n    AutoTokenizer,\n    AutoModelForSeq2SeqLM,\n    Seq2SeqTrainer,\n    Seq2SeqTrainingArguments,\n    DataCollatorForSeq2Seq\n)\nfrom rouge_score import rouge_scorer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T08:06:50.724868Z","iopub.execute_input":"2024-12-25T08:06:50.725183Z","iopub.status.idle":"2024-12-25T08:06:51.248521Z","shell.execute_reply.started":"2024-12-25T08:06:50.725150Z","shell.execute_reply":"2024-12-25T08:06:51.247744Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Отключение wandb\nos.environ[\"WANDB_DISABLED\"] = \"true\"\n\n# Проверяем использование GPU\nprint(\"Using GPU:\", torch.cuda.is_available())\n\n# Шаг 1: Загрузка датасета\nprint(\"Загрузка датасета...\")\ndataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")\nprint(dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T08:06:51.249656Z","iopub.execute_input":"2024-12-25T08:06:51.249981Z","iopub.status.idle":"2024-12-25T08:07:05.958555Z","shell.execute_reply.started":"2024-12-25T08:06:51.249955Z","shell.execute_reply":"2024-12-25T08:07:05.957863Z"}},"outputs":[{"name":"stdout","text":"Using GPU: True\nЗагрузка датасета...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/15.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"217762a0319d4f2887f240e3ecf1df20"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00003.parquet:   0%|          | 0.00/257M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97119c1a1dfb4315b71d786f91fa20cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00001-of-00003.parquet:   0%|          | 0.00/257M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc2f6e701d534df193f09224e272d316"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00002-of-00003.parquet:   0%|          | 0.00/259M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89386b00a75b499c85d1829897bdc2fd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/34.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67df7006393749a282bd482e58b0480b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/30.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20d08a339d1e4190a39307e68f81f3a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/287113 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18cf3c2148874677a6c5d45abcabe3bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/13368 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20d93a232154403dafabe264349baad6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/11490 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7831f078db9a483ba0815ea29db64b10"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['article', 'highlights', 'id'],\n        num_rows: 287113\n    })\n    validation: Dataset({\n        features: ['article', 'highlights', 'id'],\n        num_rows: 13368\n    })\n    test: Dataset({\n        features: ['article', 'highlights', 'id'],\n        num_rows: 11490\n    })\n})\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Шаг 2: Токенизация данных\nprint(\"Токенизация данных...\")\ntokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n\ndef preprocess_data(examples):\n    inputs = [\"summarize: \" + doc for doc in examples[\"article\"]]\n    model_inputs = tokenizer(inputs, max_length=512, padding=\"max_length\", truncation=True)\n    labels = tokenizer(examples[\"highlights\"], max_length=150, padding=\"max_length\", truncation=True)\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n\ntokenized_dataset = dataset.map(preprocess_data, batched=True)\n\n# Подготовка уменьшенного набора данных для тестирования\ntrain_data = tokenized_dataset[\"train\"].select(range(1000))\nval_data = tokenized_dataset[\"validation\"].select(range(500))\ntest_data = tokenized_dataset[\"test\"].select(range(500))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T08:07:05.960039Z","iopub.execute_input":"2024-12-25T08:07:05.960257Z","iopub.status.idle":"2024-12-25T08:15:07.881740Z","shell.execute_reply.started":"2024-12-25T08:07:05.960238Z","shell.execute_reply":"2024-12-25T08:15:07.881057Z"}},"outputs":[{"name":"stdout","text":"Токенизация данных...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6bb7342d12542c3a8ebc8753cb330f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12cf8ddf048341549f3e3513cbe383c3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ef4d45751a040beaff893edbbe3205d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/287113 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3b39d54a9ac4f9a95c912aa5a06ad5c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/13368 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22d2e0a70a0847c1a17ee8e9661a6cf9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/11490 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"517e019c26e646a08187f436ae2eda83"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# Шаг 3: Загрузка модели\nprint(\"Загрузка модели...\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T08:15:07.883084Z","iopub.execute_input":"2024-12-25T08:15:07.883399Z","iopub.status.idle":"2024-12-25T08:15:09.888556Z","shell.execute_reply.started":"2024-12-25T08:15:07.883367Z","shell.execute_reply":"2024-12-25T08:15:09.887709Z"}},"outputs":[{"name":"stdout","text":"Загрузка модели...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"978d887665e94ec9a2432a5f508e6799"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40f51a517b694918aca8c56be3d55b27"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"511519aefa8b40b3a0c212f76e3dbebf"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# Шаг 4: Настройка функции вычисления метрик\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n    rouge1_scores = []\n    rouge2_scores = []\n    rougeL_scores = []\n\n    for pred, label in zip(decoded_preds, decoded_labels):\n        scores = scorer.score(label, pred)\n        rouge1_scores.append(scores[\"rouge1\"].fmeasure)\n        rouge2_scores.append(scores[\"rouge2\"].fmeasure)\n        rougeL_scores.append(scores[\"rougeL\"].fmeasure)\n\n    return {\n        \"rouge1\": sum(rouge1_scores) / len(rouge1_scores),\n        \"rouge2\": sum(rouge2_scores) / len(rouge2_scores),\n        \"rougeL\": sum(rougeL_scores) / len(rougeL_scores),\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T08:15:09.889788Z","iopub.execute_input":"2024-12-25T08:15:09.890105Z","iopub.status.idle":"2024-12-25T08:15:09.897439Z","shell.execute_reply.started":"2024-12-25T08:15:09.890075Z","shell.execute_reply":"2024-12-25T08:15:09.896722Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Шаг 5: Настройка параметров обучения\nprint(\"Настройка параметров обучения...\")\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=\"./results\",\n    eval_strategy=\"epoch\",\n    learning_rate=3e-5,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=3,\n    predict_with_generate=True,\n    save_total_limit=2,\n    logging_steps=10,\n    log_level=\"info\",\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T08:15:09.898248Z","iopub.execute_input":"2024-12-25T08:15:09.898537Z","iopub.status.idle":"2024-12-25T08:15:09.968880Z","shell.execute_reply.started":"2024-12-25T08:15:09.898506Z","shell.execute_reply":"2024-12-25T08:15:09.968050Z"}},"outputs":[{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"},{"name":"stdout","text":"Настройка параметров обучения...\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Шаг 6: Создание тренера\ndata_collator = DataCollatorForSeq2Seq(tokenizer, model=model, padding=True)\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_data,\n    eval_dataset=val_data,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T08:15:09.970548Z","iopub.execute_input":"2024-12-25T08:15:09.970806Z","iopub.status.idle":"2024-12-25T08:15:10.357765Z","shell.execute_reply.started":"2024-12-25T08:15:09.970783Z","shell.execute_reply":"2024-12-25T08:15:10.357078Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Шаг 7: Обучение\nprint(\"Начало обучения...\")\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T08:15:10.358605Z","iopub.execute_input":"2024-12-25T08:15:10.358822Z","iopub.status.idle":"2024-12-25T08:17:33.111859Z","shell.execute_reply.started":"2024-12-25T08:15:10.358804Z","shell.execute_reply":"2024-12-25T08:17:33.111069Z"}},"outputs":[{"name":"stderr","text":"The following columns in the training set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: highlights, id, article. If highlights, id, article are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n","output_type":"stream"},{"name":"stdout","text":"Начало обучения...\n","output_type":"stream"},{"name":"stderr","text":"***** Running training *****\n  Num examples = 1,000\n  Num Epochs = 3\n  Instantaneous batch size per device = 8\n  Total train batch size (w. parallel, distributed & accumulation) = 8\n  Gradient Accumulation steps = 1\n  Total optimization steps = 375\n  Number of trainable parameters = 60,506,624\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [375/375 02:20, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge1</th>\n      <th>Rouge2</th>\n      <th>Rougel</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.160200</td>\n      <td>0.803429</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.065200</td>\n      <td>0.763277</td>\n      <td>0.006475</td>\n      <td>0.003222</td>\n      <td>0.005235</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.992300</td>\n      <td>0.753941</td>\n      <td>0.010614</td>\n      <td>0.005787</td>\n      <td>0.009205</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: highlights, id, article. If highlights, id, article are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 500\n  Batch size = 8\n/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\nThe following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: highlights, id, article. If highlights, id, article are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 500\n  Batch size = 8\nSaving model checkpoint to ./results/checkpoint-375\nConfiguration saved in ./results/checkpoint-375/config.json\nConfiguration saved in ./results/checkpoint-375/generation_config.json\nModel weights saved in ./results/checkpoint-375/model.safetensors\ntokenizer config file saved in ./results/checkpoint-375/tokenizer_config.json\nSpecial tokens file saved in ./results/checkpoint-375/special_tokens_map.json\nCopy vocab file to ./results/checkpoint-375/spiece.model\nThe following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: highlights, id, article. If highlights, id, article are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 500\n  Batch size = 8\n/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=375, training_loss=1.7062289098103842, metrics={'train_runtime': 141.8018, 'train_samples_per_second': 21.156, 'train_steps_per_second': 2.645, 'total_flos': 406025404416000.0, 'train_loss': 1.7062289098103842, 'epoch': 3.0})"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"# Шаг 8: Оценка на тестовой выборке\nprint(\"Оценка на тестовой выборке...\")\nmetrics = trainer.evaluate(test_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T08:17:33.112767Z","iopub.execute_input":"2024-12-25T08:17:33.113089Z","iopub.status.idle":"2024-12-25T08:17:51.554146Z","shell.execute_reply.started":"2024-12-25T08:17:33.113059Z","shell.execute_reply":"2024-12-25T08:17:51.553224Z"}},"outputs":[{"name":"stderr","text":"The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: highlights, id, article. If highlights, id, article are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n\n***** Running Evaluation *****\n  Num examples = 500\n  Batch size = 8\n","output_type":"stream"},{"name":"stdout","text":"Оценка на тестовой выборке...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [63/63 00:17]\n    </div>\n    "},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"# Шаг 9: Вывод метрик\ndef print_metrics(metrics):\n    print(\"Evaluation Metrics:\")\n    print(f\"ROUGE-1: {metrics['eval_rouge1']:.4f}\")\n    print(f\"ROUGE-2: {metrics['eval_rouge2']:.4f}\")\n    print(f\"ROUGE-L: {metrics['eval_rougeL']:.4f}\")\n    print(f\"Loss: {metrics['eval_loss']:.4f}\")\n    print(f\"Runtime (s): {metrics['eval_runtime']:.4f}\")\n    print(f\"Samples per Second: {metrics['eval_samples_per_second']:.2f}\")\n    print(f\"Steps per Second: {metrics['eval_steps_per_second']:.2f}\")\n\n# Вызов функции\nprint_metrics(metrics)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-25T08:17:51.555094Z","iopub.execute_input":"2024-12-25T08:17:51.555412Z","iopub.status.idle":"2024-12-25T08:17:51.562207Z","shell.execute_reply.started":"2024-12-25T08:17:51.555383Z","shell.execute_reply":"2024-12-25T08:17:51.561445Z"}},"outputs":[{"name":"stdout","text":"Evaluation Metrics:\nROUGE-1: 0.0051\nROUGE-2: 0.0020\nROUGE-L: 0.0042\nLoss: 0.7639\nRuntime (s): 18.4310\nSamples per Second: 27.13\nSteps per Second: 3.42\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}